##### aimldl > documents > surveys > kaggle.md
* Rev.1: 2020-03-05 (Thu)
* Draft: 2019-11-22 (Fri)

# Books on Kaggle
I found these books accidentally on Amazon.co.jp when I was looking for some NLP books in Japanese. "Kaggleで勝つデータ分析の技術" was recommended by the Amazon Recommendation system. I liked this book and ended up selecting two more books. (There was a promotion for free shipping. 5 books=free shipping to Korea, Taiwan, & Hong Kong.)

## Book Authors
* 坂本 俊之, [データサイエンスの森　Kaggleの歩き]
* 石原 祥太郎, 村田 秀樹, 実践Data Scienceシリーズ PythonではじめるKaggleスタートブック
* 門脇 大輔, 阪田 隆司, 保坂 桂佑, 平松 雄司, Kaggleで勝つデータ分析の技術

#### 著者について
石原 祥太郎(u++), Kaggle Master(https://kaggle.com/sishihara)
・2019年4月に「PetFinder.my Adoption Prediction」コンペで優勝
・2019年12月には「Kaggle Days Tokyo」でのコンペ開催にも携わる
・2019年3月に公開したQiitaのKaggle入門記事は1600いいねを達成
・日本経済新聞社でデータ分析に従事

村田 秀樹(カレー)
・Kaggle Master(https://kaggle.com/currypurin)
・2018年8月に「Santander Value Prediction Challenge」コンペでソロゴールドメダル獲得(8位)
・2019年6月に「LANL Earthquake Prediction」コンペで3位入賞
・Kaggle入門者のために書いた同人誌の『Kaggleのチュートリアル』は累計2500部を突破
・専業Kagglerとして,2018年7月より活動している


### 2. [データサイエンスの森　Kaggleの歩き](https://www.amazon.co.jp/データサイエンスの森-Kaggleの歩き方-坂本-俊之/dp/4863542933/ref=pd_bxgy_14_img_3/355-0469201-0950500?_encoding=UTF8&pd_rd_i=4863542933&pd_rd_r=9073b9d2-958c-4a96-be01-0759e40a9fbf&pd_rd_w=d1fPJ&pd_rd_wg=k3uPd&pf_rd_p=b25bd748-082b-4f2a-b724-125316a35a9c&pf_rd_r=77FSZ8RJ5SB04DQT2GDE&psc=1&refRID=77FSZ8RJ5SB04DQT2GDE)
* 2019/10/22, 坂本 俊之 (著), 単行本 ￥2,904
* I ordered it on 2020-03-04.

#### [目次]
```
01 Kaggleとは
02 はじめてのKaggle
03 ノートブックを使いこなそう
04 Kaggleにおけるコンペティション
05 Kaggleマスターへの道
APPENDIX よく使われる機械学習ライブラリ
```
#### Selected Reviews
* 期待外れ。ディスカッションにこんなメッセージ送ったら、こういうメッセージが返ってきました、Google翻訳使えば読めます、とかどうでもいい。
Kaggleをこれから始めようと思う人は、こんなダラダラ書いた本をダラダラ読むよりも、Qiitaの記事見ながら1日でも早くKaggle始めたほうが良い。
* 帯に書いてある事が全てです。
kaggleにたどり着いたものの、英語が超苦手で使い方に悩んでいる人のための解説本。一通り英語ができる人でも、流し読みしておけば若干作業効率が上がるかも知れません。

### 3. [実践Data Scienceシリーズ PythonではじめるKaggleスタートブック](https://www.amazon.co.jp/%E5%AE%9F%E8%B7%B5Data-Science%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA-Python%E3%81%A7%E3%81%AF%E3%81%98%E3%82%81%E3%82%8BKaggle%E3%82%B9%E3%82%BF%E3%83%BC%E3%83%88%E3%83%96%E3%83%83%E3%82%AF-KS%E6%83%85%E5%A0%B1%E7%A7%91%E5%AD%A6%E5%B0%82%E9%96%80%E6%9B%B8-%E7%A5%A5%E5%A4%AA%E9%83%8E/dp/4065190061/ref=pd_lutyp_crty_cxhsh_1_2/358-9494963-0927933?_encoding=UTF8&pd_rd_i=4065190061&pd_rd_r=f02fabaf-16c4-468a-bfcb-2aa137af305b&pd_rd_w=zZ1GE&pd_rd_wg=ysCCo&pf_rd_p=3a8b6213-8c75-462f-a876-fcae4b498ee8&pf_rd_r=0XY7F45JHDSKJR3MDQ20&psc=1&refRID=0XY7F45JHDSKJR3MDQ20)
* 講談社, 2020/3/19, 石原 祥太郎 (著), 村田 秀樹 (著), 単行本（ソフトカバー）￥2,200, 192ページ
* I ordered it on 2020-03-04 (Reservation)

#### [目次]
```
第1章 Kaggleを知る
1.1 Kaggleとは
1.2 Kaggleで用いる機械学習
1.3 Kaggleのアカウントの作成
1.4 Competitionsページの概要
1.5 環境構築不要な「Notebooks」の使い方

第2章 Titanicに取り組む
2.1 まずはsubmit! 順位表に載ってみよう
2.2 全体像を把握! submitまでの処理の流れを見てみよう
2.3 次の一手を見い出す! 探索的データ分析をしてみよう
2.4 ここで差がつく! 仮説に基づいて新しい特徴量を作ってみよう
2.5 勾配ブースティングが最強?! いろいろな機械学習アルゴリズムを使ってみよう
2.6 機械学習アルゴリズムのお気持ち?! ハイパーパラメータを調整してみよう
2.7 submitのその前に! 「Cross Validation」の大切さを知ろう
2.8 三人寄れば文殊の知恵! アンサンブルを体験しよう.

第3章 Titanicの先に行く
3.1 複数テーブルを扱う
3.2 画像データを扱う
3.3 テキストデータを扱う

第4章 さらなる学びのために
4.1 参加するコンペの選び方
4.2 初学者にお勧めの戦い方
4.3 分析環境の選択肢
4.4 お勧めの資料・文献・リンク

付録A サンプルコード詳細解説
A.1 第2章 Titanicに取り組む
A.2 第3章 Titanicの先に行く
```

#### 内容紹介
シリーズの第2弾は、初学者向けのKaggle入門書の決定版!

★「Kaggleで勝つ」準備をしよう!★
初学者が「Kaggleに何となく興味ある」状態から「実際のコンペに参加できる」状態になれるような内容を目指しました。

・サンプルコードの詳細な解説があるから、しっかり身につく!
・優勝チームと専業Kagglerのコンビによる、安定のわかりやすさ!
・充実の本音対談で、やさしくサポート!
・初学者や手探りでやっているが体系的な知識を得たい人に最適。
★本書のサポートページ https://github.com/upura/python-kaggle-start-book
★実践Data Scienceシリーズ: https://www.kspub.co.jp/book/series/S069.html

### 4. [파이썬 머신러닝 완벽 가이드 다양한 캐글 예제와 함께 기초 알고리즘부터 최신 기법까지 배우는](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791158391928&orderClick=LAG&Kc=)
* 권철민 지음, 위키북스, 2020년 02월 07일 출간, 648쪽, 정가: 38,000원, 판매가: 34,200원

```
자세한 이론 설명과 파이썬 실습을 통해 머신러닝을 완벽하게 배울 수 있습니다!
《파이썬 머신러닝 완벽 가이드》는 이론 위주의 머신러닝 책에서 탈피해 다양한 실전 예제를 직접 구현해 보면서 머신러닝을 체득할 수 있도록 만들었습니다. 캐글과 UCI 머신러닝 리포지토리에서 난이도가 있는 실습 데이터를 기반으로 실전 예제를 구성했고, XGBoost, LightGBM, 스태킹 기법 등 캐글의 많은 데이터 사이언스에서 애용하는 최신 알고리즘과 기법에 대해 매우 상세하게 설명했습니다. 이번 개정판에서는 사이킷런 및 기타 라이브러리의 업데이트에 따른 전반적인 내용 및 소스코드 업데이트와 함께 질의 사항이 많은 부분들에 대한 상세한 설명을 추가했습니다.
```
#### 목차
```
▣ 1장: 파이썬 기반의 머신러닝과 생태계 이해
1.1. 머신러닝의 개념
__머신러닝의 분류
__데이터 전쟁
__파이썬과 R 기반의 머신러닝 비교
1.2. 파이썬 머신러닝 생태계를 구성하는 주요 패키지
__파이썬 머신러닝을 위한 S/W 설치
1.3. 넘파이
__넘파이 ndarray 개요
__ndarray의 데이터 타입
__ndarray를 편리하게 생성하기 - arange, zeros, ones
__ndarray의 차원과 크기를 변경하는 reshape( )
__넘파이의 ndarray의 데이터 세트 선택하기 - 인덱싱(Indexing)
__행렬의 정렬 - sort( )와 argsort( )
__선형대수 연산 - 행렬 내적과 전치 행렬 구하기
1.4. 데이터 핸들링 - 판다스
__판다스 시작 - 파일을 DataFrame으로 로딩, 기본 API
__DataFrame과 리스트, 딕셔너리, 넘파이 ndarray 상호 변환
__DataFrame의 컬럼 데이터 세트 생성과 수정
__DataFrame 데이터 삭제
__Index 객체
__데이터 셀렉션 및 필터링
__정렬, Aggregation 함수, GroupBy 적용
__결손 데이터 처리하기
__apply lambda 식으로 데이터 가공
1.5. 정리

▣ 2장: 사이킷런으로 시작하는 머신러닝
2.1. 사이킷런 소개와 특징
2.2. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기
2.3. 사이킷런의 기반 프레임워크 익히기
__Estimator 이해 및 fit( ), predict( ) 메서드
__사이킷런의 주요 모듈
__내장된 예제 데이터 세트
2.4. Model Selection 모듈 소개
__학습/테스트 데이터 세트 분리 - train_test_split()
__교차 검증
__GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에
2.5. 데이터 전처리
__데이터 인코딩
__피처 스케일링과 정규화
__StandardScaler
__MinMaxScaler
__학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점
2.6. 사이킷런으로 수행하는 타이타닉 생존자 예측
2.7. 정리

▣ 3장: 평가
3.1. 정확도(Accuracy)
3.2. 오차 행렬
3.3. 정밀도와 재현율
__정밀도/재현율 트레이드오프
__정밀도와 재현율의 맹점
3.4. F1 스코어
3.5. ROC 곡선과 AUC
3.6. 피마 인디언 당뇨병 예측
3.7. 정리

▣ 4장: 분류
4.1. 분류(Classification)의 개요
4.2. 결정 트리
__결정 트리 모델의 특징
__결정 트리 파라미터
__결정 트리 모델의 시각화
__결정 트리 과적합(Overfitting)
__결정 트리 실습 - 사용자 행동 인식 데이터 세트
4.3. 앙상블 학습
__앙상블 학습 개요
__보팅 유형 - 하드 보팅(Hard Voting)과 소프트 보팅(Soft Voting)
__보팅 분류기(Voting Classifier)
4.4. 랜덤 포레스트
__랜덤 포레스트의 개요 및 실습
__랜덤 포레스트 하이퍼 파라미터 및 튜닝
4.5. GBM(Gradient Boosting Machine)
__GBM의 개요 및 실습
__GBM 하이퍼 파라미터 및 튜닝
4.6. XGBoost(eXtra Gradient Boost)
__XGBoost 개요
__XGBoost 설치하기
__파이썬 래퍼 XGBoost 하이퍼 파라미터
__파이썬 래퍼 XGBoost 적용 - 위스콘신 유방암 예측
__사이킷런 래퍼 XGBoost의 개요 및 적용
4.7. LightGBM
__LightGBM 설치
__LightGBM 하이퍼 파라미터
__하이퍼 파라미터 튜닝 방안
__파이썬 래퍼 LightGBM과 사이킷런 래퍼 XGBoost, LightGBM 하이퍼 파라미터 비교
__LightGBM 적용 - 위스콘신 유방암 예측
4.8. 분류 실습 - 캐글 산탄데르 고객 만족 예측
__데이터 전처리
__XGBoost 모델 학습과 하이퍼 파라미터 튜닝
__LightGBM 모델 학습과 하이퍼 파라미터 튜닝
4.9. 분류 실습 - 캐글 신용카드 사기 검출
__언더 샘플링과 오버 샘플링의 이해
__데이터 일차 가공 및 모델 학습/예측/평가
__데이터 분포도 변환 후 모델 학습/예측/평가
__이상치 데이터 제거 후 모델 학습/예측/평가
__SMOTE 오버 샘플링 적용 후 모델 학습/예측/평가
4.10. 스태킹 앙상블
__기본 스태킹 모델
__CV 세트 기반의 스태킹
4.11. 정리

▣ 5장: 회귀
5.1. 회귀 소개
5.2. 단순 선형 회귀를 통한 회귀 이해
5.3. 비용 최소화하기 - 경사 하강법(Gradient Descent) 소개
5.4. 사이킷런 LinearRegression을 이용한 보스턴 주택 가격 예측
__LinearRegression 클래스 - Ordinary Least Squares
__회귀 평가 지표
__LinearRegression을 이용해 보스턴 주택 가격 회귀 구현
5.5. 다항 회귀와 과(대)적합/과소적합 이해
__다항 회귀 이해
__다항 회귀를 이용한 과소적합 및 과적합 이해
__편향-분산 트레이드오프(Bias-Variance Trade off)
5.6. 규제 선형 모델 - 릿지, 라쏘, 엘라스틱넷
__규제 선형 모델의 개요
__릿지 회귀
__라쏘 회귀
__엘라스틱넷 회귀
__선형 회귀 모델을 위한 데이터 변환
5.7. 로지스틱 회귀
5.8. 회귀 트리
5.9. 회귀 실습 - 자전거 대여 수요 예측
__데이터 클렌징 및 가공
__로그 변환, 피처 인코딩과 모델 학습/예측/평가
5.10. 회귀 실습 - 캐글 주택 가격: 고급 회귀 기법
__데이터 사전 처리(Preprocessing)
__선형 회귀 모델 학습/예측/평가
__회귀 트리 모델 학습/예측/평가
__회귀 모델의 예측 결과 혼합을 통한 최종 예측
__스태킹 앙상블 모델을 통한 회귀 예측
5.11. 정리

▣ 6장: 차원 축소
6.1. 차원 축소(Dimension Reduction) 개요
6.2. PCA(Principal Component Analysis)
__PCA 개요
6.3. LDA(Linear Discriminant Analysis)
__LDA 개요
__붓꽃 데이터 세트에 LDA 적용하기
6.4. SVD(Singular Value Decomposition)
__SVD 개요
__사이킷런 TruncatedSVD 클래스를 이용한 변환
6.5. NMF(Non-Negative Matrix Factorization)
__NMF 개요
6.6. 정리

▣ 7장: 군집화
7.1. K-평균 알고리즘 이해
__사이킷런 KMeans 클래스 소개
__K-평균을 이용한 붓꽃 데이터 세트 군집화
__군집화 알고리즘 테스트를 위한 데이터 생성
7.2. 군집 평가(Cluster Evaluation)
__실루엣 분석의 개요
__붓꽃 데이터 세트를 이용한 군집 평가
__군집별 평균 실루엣 계수의 시각화를 통한 군집 개수 최적화 방법
7.3. 평균 이동
__평균 이동(Mean Shift)의 개요
7.4. GMM(Gaussian Mixture Model)
__GMM(Gaussian Mixture Model) 소개
__GMM을 이용한 붓꽃 데이터 세트 군집화
__GMM과 K-평균의 비교
7.5. DBSCAN
__DBSCAN 개요
__DBSCAN 적용하기 - 붓꽃 데이터 세트
__DBSCAN 적용하기 - make_circles( ) 데이터 세트
7.6. 군집화 실습 - 고객 세그먼테이션
__고객 세그먼테이션의 정의와 기법
__데이터 세트 로딩과 데이터 클렌징
__RFM 기반 데이터 가공
__RFM 기반 고객 세그먼테이션
7.7. 정리

▣ 8장: 텍스트 분석
NLP이냐 텍스트 분석이냐?
8.1. 텍스트 분석 이해
__텍스트 분석 수행 프로세스
__파이썬 기반의 NLP, 텍스트 분석 패키지
8.2. 텍스트 사전 준비 작업(텍스트 전처리) - 텍스트 정규화
__클렌징
__텍스트 토큰화
__스톱 워드 제거
__Stemming과 Lemmatization
8.3. Bag of Words - BOW
__BOW 피처 벡터화
__사이킷런의 Count 및 TF-IDF 벡터화 구현: CountVectorizer, TfidfVectorizer
__BOW 벡터화를 위한 희소 행렬
__희소 행렬 - COO 형식
__희소 행렬 - CSR 형식
8.4. 텍스트 분류 실습 - 20 뉴스그룹 분류
__텍스트 정규화
__피처 벡터화 변환과 머신러닝 모델 학습/예측/평가
__사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합
8.5. 감성 분석
__감성 분석 소개
__지도학습 기반 감성 분석 실습 - IMDB 영화평
__비지도학습 기반 감성 분석 소개
__SentiWordNet을 이용한 감성 분석
__VADER를 이용한 감성 분석
8.6. 토픽 모델링(Topic Modeling) - 20 뉴스그룹
8.7. 문서 군집화 소개와 실습(Opinion Review 데이터 세트)
__문서 군집화 개념
__Opinion Review 데이터 세트를 이용한 문서 군집화 수행하기
__군집별 핵심 단어 추출하기
8.8. 문서 유사도
__문서 유사도 측정 방법 - 코사인 유사도
__두 벡터 사잇각
__Opinion Review 데이터 세트를 이용한 문서 유사도 측정
8.9. 한글 텍스트 처리 - 네이버 영화 평점 감성 분석
__한글 NLP 처리의 어려움
__KoNLPy 소개
__데이터 로딩
8.10. 텍스트 분석 실습-캐글 Mercari Price Suggestion Challenge
__데이터 전처리
__피처 인코딩과 피처 벡터화
__릿지 회귀 모델 구축 및 평가
__LightGBM 회귀 모델 구축과 앙상블을 이용한 최종 예측 평가
8.11. 정리

▣ 9장: 추천 시스템
9.1. 추천 시스템의 개요와 배경
__추천 시스템의 개요
__온라인 스토어의 필수 요소, 추천 시스템
__추천 시스템의 유형
9.2. 콘텐츠 기반 필터링 추천 시스템
9.3. 최근접 이웃 협업 필터링
9.4. 잠재 요인 협업 필터링
__잠재 요인 협업 필터링의 이해
__행렬 분해의 이해
__확률적 경사 하강법을 이용한 행렬 분해
9.5. 콘텐츠 기반 필터링 실습 - TMDB 5000 영화 데이터 세트
__장르 속성을 이용한 영화 콘텐츠 기반 필터링
__데이터 로딩 및 가공
__장르 콘텐츠 유사도 측정
__장르 콘텐츠 필터링을 이용한 영화 추천
9.6. 아이템 기반 최근접 이웃 협업 필터링 실습
__데이터 가공 및 변환
__영화 간 유사도 산출
__아이템 기반 최근접 이웃 협업 필터링으로 개인화된 영화 추천
9.7. 행렬 분해를 이용한 잠재 요인 협업 필터링 실습
9.8. 파이썬 추천 시스템 패키지 - Surprise
__Surprise 패키지 소개
__Surprise를 이용한 추천 시스템 구축
__Surprise 주요 모듈 소개
__Surprise 추천 알고리즘 클래스
__베이스라인 평점
__교차 검증과 하이퍼 파라미터 튜닝
__Surprise를 이용한 개인화 영화 추천 시스템 구축
9.9. 정리
출판사 서평
```
### 5. [Kaggleで勝つデータ分析の技術](https://www.amazon.co.jp/Kaggleで勝つデータ分析の技術-門脇-大輔/dp/4297108437/ref=sr_1_1?qid=1574393596&s=books&sr=1-1&text=保坂+桂佑)
* 技術評論社 (2019/10/9), 門脇 大輔 (著), 阪田 隆司 (著), 保坂 桂佑 (著), 平松 雄司 (著), 単行本（ソフトカバー）￥3,608
* I ordered it on 2020-03-04.

#### [目次](https://www.amazon.co.jp/dp/toc/4297108437/ref=dp_toc?_encoding=UTF8&n=465392)
```
第1章 分析コンペとは?
1.1 分析コンペって何?
1.1.1 何をするものか
1.1.2 予測結果の提出と順位表(Leaderboard)
1.1.3 チームでの参加
1.1.4 入賞賞金・特典
1.2 分析コンペのプラットフォーム
1.2.1 Kaggle
1.2.2 Rankings(ランキング・称号制度)
1.2.3 Kernel
1.2.4 Discussion
1.2.5 Datasets
1.2.6 API
1.2.7 Newsfeed
1.2.8 開催された分析コンペの種類と具体例
1.2.9 分析コンペのフォーマット
1.3 分析コンペに参加してから終わるまで
1.3.1 分析コンペに参加
1.3.2 規約に同意
1.3.3 データをダウンロード
1.3.4 予測値の作成
1.3.5 予測値の提出
1.3.6 Public Leaderboardをチェック
1.3.7 最終予測値を選ぶ
1.3.8 Private Leaderboardをチェック
1.4 分析コンペに参加する意義
1.4.1 賞金を得る
1.4.2 称号やランキングを得る
1.4.3 実データを用いた分析の経験・技術を得る
1.4.4 データサイエンティストとのつながりを得る
1.4.5 就業機会を得る
1.5 上位を目指すためのポイント
1.5.1 タスクと評価指標
1.5.2 特徴量の作成
1.5.3 モデルの作成
1.5.4 モデルの評価
1.5.5 モデルのチューニング
1.5.6 アンサンブル
1.5.7 分析コンペの流れ
Column 計算リソース

第2章 タスクと評価指標
2.1 分析コンペにおけるタスクの種類
2.1.1 回帰タスク
2.1.2 分類タスク
2.1.3 レコメンデーション
2.1.4 その他のタスク
2.2 分析コンペのデータセット
2.2.1 テーブルデータ
2.2.2 外部データ
2.2.3 時系列データ
2.2.4 画像や自然言語などのデータ
2.3 評価指標
2.3.1 評価指標(evaluation metrics)とは
2.3.2 回帰における評価指標
2.3.3 二値分類における評価指標〜正例か負例かを予測値とする場合
2.3.4 二値分類における評価指標〜正例である確率を予測値とする場合
2.3.5 多クラス分類における評価指標
2.3.6 レコメンデーションにおける評価指標
2.4 評価指標と目的関数
2.4.1 評価指標と目的関数の違い
2.4.2 カスタム評価指標とカスタム目的関数
2.5 評価指標の最適化
2.5.1 評価指標の最適化のアプローチ
2.5.2 閾値の最適化
2.5.3 閾値の最適化をout-of-foldで行うべきか?
Column out-of-foldとは?
2.5.4 予測確率とその調整
2.6 評価指標の最適化の例
2.6.1 balanced accuracyの最適化
2.6.2 mean-F1における閾値の最適化
2.6.3 quadratic weighted kappaにおける閾値の最適化
2.6.4 カスタム目的関数での評価指標の近似によるMAEの最適化
2.6.5 MCCのPR-AUCによる近似とモデル選択
2.7 リーク(data leakage) 107
2.7.1 予測に有用な情報が想定外に漏れている意味でのリーク
2.7.2 バリデーションの枠組みの誤りという意味でのリーク

第3章 特徴量の作成
3.1 本章の構成
3.2 モデルと特徴量
3.2.1 モデルと特徴量
3.2.2 ベースラインとなる特徴量
3.2.3 決定木の気持ちになって考える
3.3 欠損値の扱い
3.3.1 欠損値のまま取り扱う
3.3.2 欠損値を代表値で埋める
3.3.3 欠損値を他の変数から予測する
3.3.4 欠損値から新たな特徴量を作成する
3.3.5 データ上の欠損の認識
3.4 数値変数の変換
3.4.1 標準化(standardization)
Column データ全体の数値を利用して変換を行うときに、学習データのみを使うか、テストデータも使うか
3.4.2 Min-Maxスケーリング
3.4.3 非線形変換
3.4.4 clipping
3.4.5 binning
3.4.6 順位への変換
3.4.7 RankGauss
3.5 カテゴリ変数の変換
3.5.1 one-hot encoding
3.5.2 label encoding
3.5.3 feature hashing
3.5.4 frequency encoding
3.5.5 target encoding
3.5.6 embedding
3.5.7 順序変数の扱い
3.5.8 カテゴリ変数の値の意味を抽出する
3.6 日付・時刻を表す変数の変換
3.6.1 日付・時刻を表す変数の変換のポイント
3.6.2 日付・時刻を表す変数の変換による特徴量
3.7 変数の組み合わせ
3.8 他のテーブルの結合
3.9 集約して統計量をとる
3.9.1 単純な統計量をとる
3.9.2 時間的な統計量をとる
3.9.3 条件を絞る
3.9.4 集計する単位を変える
3.9.5 ユーザ側でなく、アイテム側に注目する
3.10 時系列データの扱い
3.10.1 時系列データとは?
3.10.2 予測する時点より過去の情報のみを使う
3.10.3 ワイドフォーマットとロングフォーマット
3.10.4 ラグ特徴量
3.10.5 時点と紐付いた特徴量を作る
3.10.6 予測に使えるデータの期間
3.11 次元削減・教師なし学習による特徴量
3.11.1 主成分分析(PCA)
3.11.2 非負値行列因子分解(NMF)
3.11.3 Latent Dirichlet Allocation(LDA)
3.11.4 線形判別分析(LDA)
3.11.5 t-SNE、UMAP
3.11.6 オートエンコーダ
3.11.7 クラスタリング
3.12 その他のテクニック
3.12.1 背景にあるメカニズムから考える
3.12.2 レコード間の関係性に注目する
3.12.3 相対値に注目する
3.12.4 位置情報に注目する
3.12.5 自然言語処理の手法
3.12.6 自然言語処理の手法の応用
3.12.7 トピックモデルの応用によるカテゴリ変数の変換
3.12.8 画像特徴量を扱う手法
3.12.9 decision tree feature transformation
3.12.10 匿名化されたデータの変換前の値を推測する
3.12.11 データの誤りを修正する
3.13 分析コンペにおける特徴量の作成の例
3.13.1 Kaggleの「Recruit Restaurant Visitor Forecasting」
3.13.2 Kaggleの「Santander Product Recommendation」
3.13.3 Kaggleの「Instacart Market Basket Analysis」
3.13.4 KDD Cup 2015
3.13.5 分析コンペにおけるその他のテクニックの例

第4章 モデルの作成
4.1 モデルとは何か?
4.1.1 モデルとは何か?
4.1.2 モデル作成の流れ
4.1.3 モデルに関連する用語とポイント
4.2 分析コンペで使われるモデル
4.3 GBDT(勾配ブースティング木)
4.3.1 GBDTの概要
4.3.2 GBDTの特徴
4.3.3 GBDTの主なライブラリ
4.3.4 GBDTの実装
4.3.5 xgboostの使い方のポイント
4.3.6 lightgbm
4.3.7 catboost
Column xgboostのアルゴリズムの解説
4.4 ニューラルネット
4.4.1 ニューラルネットの概要
4.4.2 ニューラルネットの特徴
4.4.3 ニューラルネットの主なライブラリ
4.4.4 ニューラルネットの実装
4.4.5 kerasの使い方のポイント
4.4.6 参考になるソリューション - 多層パーセプトロン
4.4.7 参考になるソリューション - 最近のニューラルネットの発展
4.5 線形モデル
4.5.1 線形モデルの概要
4.5.2 線形モデルの特徴
4.5.3 線形モデルの主なライブラリ
4.5.4 線形モデルの実装
4.5.5 線形モデルの使い方のポイント
4.6 その他のモデル
4.6.1 k近傍法(k-nearest neighbor algorithm、kNN)
4.6.2 ランダムフォレスト(Random Forest、RF)
4.6.3 Extremely Randomized Trees(ERT)
4.6.4 Regularized Greedy Forest(RGF)
4.6.5 Field-aware Factorization Machines(FFM)
4.7 モデルのその他のポイントとテクニック
4.7.1 欠損値がある場合
4.7.2 特徴量の数が多い場合
4.7.3 目的変数に1対1で対応するテーブルでない場合
4.7.4 pseudo labeling
Column 分析コンペ用のクラスやフォルダの構成

第5章 モデルの評価
5.1 モデルの評価とは?
5.2 バリデーションの手法
5.2.1 hold-out法
5.2.2 クロスバリデーション
5.2.3 stratified k-fold
5.2.4 group k-fold
5.2.5 leave-one-out
5.3 時系列データのバリデーション手法
5.3.1 時系列データのhold-out法
5.3.2 時系列データのクロスバリデーション(時系列に沿って行う方法)
5.3.3 時系列データのクロスバリデーション(単純に時間で分割する方法)
5.3.4 時系列データのバリデーションの注意点
5.3.5 Kaggleの「Recruit Restaurant Visitor Forecasting」
5.3.6 Kaggleの「Santander Product Recommendation」
5.4 バリデーションのポイントとテクニック
5.4.1 バリデーションを行う目的
5.4.2 学習データとテストデータの分割をまねる
5.4.3 学習データとテストデータの分布が違う場合
5.4.4 Leaderboardの情報を利用する
5.4.5 バリデーションデータやPublic Leaderboardへの過剰な適合
5.4.6 クロスバリデーションのfoldごとに特徴量を作り直す
5.4.7 使える学習データを増やす

第6章 モデルのチューニング
6.1 パラメータチューニング
6.1.1 ハイパーパラメータの探索手法
6.1.2 パラメータチューニングで設定すること
6.1.3 パラメータチューニングのポイント
6.1.4 ベイズ最適化でのパラメータ探索
6.1.5 GBDTのパラメータおよびそのチューニング
Column xgboostの具体的なパラメータチューニングの方法
6.1.6 ニューラルネットのパラメータおよびそのチューニング
Column 多層パーセプトロンの具体的なパラメータチューニングの方法
6.1.7 線形モデルのパラメータおよびそのチューニング
6.2 特徴選択および特徴量の重要度
6.2.1 単変量統計を用いる方法
6.2.2 特徴量の重要度を用いる方法
6.2.3 反復して探索する方法
6.3 クラスの分布が偏っている場合
Column ベイズ最適化およびTPEのアルゴリズム

第7章 アンサンブル
7.1 アンサンブルとは?
7.2 シンプルなアンサンブル手法
7.2.1 平均、加重平均
7.2.2 多数決、重みづけ多数決
7.2.3 注意点とその他のテクニック
7.3 スタッキング
7.3.1 スタッキングの概要
7.3.2 特徴量作成の方法としてのスタッキング
7.3.3 スタッキングの実装
7.3.4 スタッキングのポイント
7.3.5 hold-outデータへの予測値を用いたアンサンブル
7.4 どんなモデルをアンサンブルすると良いか?
7.4.1 多様なモデルを使う
7.4.2 ハイパーパラメータを変える
7.4.3 特徴量を変える
7.4.4 問題のとらえ方を変える
7.4.5 スタッキングに含めるモデルの選択
7.5 分析コンペにおけるアンサンブルの例
7.5.1 Kaggleの「Otto Group Product Classification Challenge」
7.5.2 Kaggleの「Home Depot Product Search Relevance」
7.5.3 Kaggleの「Home Credit Default Risk」

付 録
A.1 分析コンペの参考資料
A.2 参考文献
A.3 本書で参照した分析コンペ
索引
著者プロフィール

詳細目次は以下で確認できます
```
#### [詳細目次](https://gihyo.jp/book/2019/978-4-297-10843-4#toc)
The table of contents above is already very detailed. I was blown away to see "detailed" table of contents. Wow!

```
第1章　分析コンペとは?
1.1 分析コンペって何？
1.1.1 何をするものか
1.1.2 予測結果の提出と順位表（Leaderboard）
1.1.3 チームでの参加
1.1.4 入賞賞金・特典
1.2 分析コンペのプラットフォーム
1.2.1 Kaggle
1.2.2 Rankings（ランキング・称号制度）
1.2.3 Kernel
1.2.4 Discussion
1.2.5 Datasets
1.2.6 API
1.2.7 Newsfeed
1.2.8 開催された分析コンペの種類と具体例
1.2.9 分析コンペのフォーマット
1.3 分析コンペに参加してから終わるまで
1.3.1 分析コンペに参加
1.3.2 規約に同意
1.3.3 データをダウンロード
1.3.4 予測値の作成
1.3.5 予測値の提出
1.3.6 Public Leaderboardをチェック
1.3.7 最終予測値を選ぶ
1.3.8 Private Leaderboardをチェック
1.4 分析コンペに参加する意義
1.4.1 賞金を得る
1.4.2 称号やランキングを得る
1.4.3 実データを用いた分析の経験・技術を得る
1.4.4 データサイエンティストとのつながりを得る
1.4.5 就業機会を得る
1.5 上位を目指すためのポイント
1.5.1 タスクと評価指標
1.5.2 特徴量の作成
1.5.3 モデルの作成
1.5.4 モデルの評価
1.5.5 モデルのチューニング
1.5.6 アンサンブル
1.5.7 分析コンペの流れ
Column 　計算リソース
第2章　タスクと評価指標
2.1 分析コンペにおけるタスクの種類
2.1.1 回帰タスク
2.1.2 分類タスク
2.1.3 レコメンデーション
2.1.4 その他のタスク
2.2 分析コンペのデータセット
2.2.1 テーブルデータ
2.2.2 外部データ
2.2.3 時系列データ
2.2.4 画像や自然言語などのデータ
2.3 評価指標
2.3.1 評価指標（evaluation metrics）とは
2.3.2 回帰における評価指標
2.3.3 二値分類における評価指標〜正例か負例かを予測値とする場合
2.3.4 二値分類における評価指標〜正例である確率を予測値とする場合
2.3.5 多クラス分類における評価指標
2.3.6 レコメンデーションにおける評価指標
2.4 評価指標と目的関数
2.4.1 評価指標と目的関数の違い
2.4.2 カスタム評価指標とカスタム目的関数
2.5 評価指標の最適化
2.5.1 評価指標の最適化のアプローチ
2.5.2 閾値の最適化
2.5.3 閾値の最適化をout-of-foldで行うべきか？
Column out-of-foldとは？
2.5.4 予測確率とその調整
2.6 評価指標の最適化の例
2.6.1 balanced accuracyの最適化
2.6.2 mean-F1における閾値の最適化
2.6.3 quadratic weighted kappaにおける閾値の最適化
2.6.4 カスタム目的関数での評価指標の近似によるMAEの最適化
2.6.5 MCCのPR-AUCによる近似とモデル選択
2.7 リーク（data leakage）
2.7.1 予測に有用な情報が想定外に漏れている意味でのリーク
2.7.2 バリデーションの枠組みの誤りという意味でのリーク
第3章　特徴量の作成
3.1 本章の構成
3.2 モデルと特徴量
3.2.1 モデルと特徴量
3.2.2 ベースラインとなる特徴量
3.2.3 決定木の気持ちになって考える
3.3 欠損値の扱い
3.3.1 欠損値のまま取り扱う
3.3.2 欠損値を代表値で埋める
3.3.3 欠損値を他の変数から予測する
3.3.4 欠損値から新たな特徴量を作成する
3.3.5 データ上の欠損の認識
3.4 数値変数の変換
3.4.1 標準化（standardization）
Column データ全体の数値を利用して変換を行うときに，学習データのみを使うか，テストデータも使うか
3.4.2 Min-Maxスケーリング
3.4.3 非線形変換
3.4.4 clipping
3.4.5 binning
3.4.6 順位への変換
3.4.7 RankGauss
3.5 カテゴリ変数の変換
3.5.1 one-hot encoding
3.5.2 label encoding
3.5.3 feature hashing
3.5.4 frequency encoding
3.5.5 target encoding
3.5.6 embedding
3.5.7 順序変数の扱い
3.5.8 カテゴリ変数の値の意味を抽出する
3.6 日付・時刻を表す変数の変換
3.6.1 日付・時刻を表す変数の変換のポイント
3.6.2 日付・時刻を表す変数の変換による特徴量
3.7 変数の組み合わせ
3.8 他のテーブルの結合
3.9 集約して統計量をとる
3.9.1 単純な統計量をとる
3.9.2 時間的な統計量をとる
3.9.3 条件を絞る
3.9.4 集計する単位を変える
3.9.5 ユーザ側でなく，アイテム側に注目する
3.10 時系列データの扱い
3.10.1 時系列データとは？
3.10.2 予測する時点より過去の情報のみを使う
3.10.3 ワイドフォーマットとロングフォーマット
3.10.4 ラグ特徴量
3.10.5 時点と紐付いた特徴量を作る
3.10.6 予測に使えるデータの期間
3.11 次元削減・教師なし学習による特徴量
3.11.1 主成分分析（PCA）
3.11.2 非負値行列因子分解（NMF）
3.11.3 Latent Dirichlet Allocation（LDA）
3.11.4 線形判別分析（LDA）
3.11.5 t-SNE，UMAP
3.11.6 オートエンコーダ
3.11.7 クラスタリング
3.12 その他のテクニック
3.12.1 背景にあるメカニズムから考える
3.12.2 レコード間の関係性に注目する
3.12.3 相対値に注目する
3.12.4 位置情報に注目する
3.12.5 自然言語処理の手法
3.12.6 自然言語処理の手法の応用
3.12.7 トピックモデルの応用によるカテゴリ変数の変換
3.12.8 画像特徴量を扱う手法
3.12.9 decision tree feature transformation
3.12.10 匿名化されたデータの変換前の値を推測する
3.12.11 データの誤りを修正する
3.13 分析コンペにおける特徴量の作成の例
3.13.1 Kaggleの「Recruit Restaurant Visitor Forecasting」
3.13.2 Kaggleの「Santander Product Recommendation」
3.13.3 Kaggleの「Instacart Market Basket Analysis」
3.13.4 KDD Cup 2015
3.13.5 分析コンペにおけるその他のテクニックの例
第4章　モデルの作成
4.1 モデルとは何か？
4.1.1 モデルとは何か？
4.1.2 モデル作成の流れ
4.1.3 モデルに関連する用語とポイント
4.2 分析コンペで使われるモデル
4.3 GBDT（勾配ブースティング木）
4.3.1 GBDTの概要
4.3.2 GBDTの特徴
4.3.3 GBDTの主なライブラリ
4.3.4 GBDTの実装
4.3.5 xgboostの使い方のポイント
4.3.6 lightgbm
4.3.7 catboost
Column xgboostのアルゴリズムの解説
4.4 ニューラルネット
4.4.1 ニューラルネットの概要
4.4.2 ニューラルネットの特徴
4.4.3 ニューラルネットの主なライブラリ
4.4.4 ニューラルネットの実装
4.4.5 kerasの使い方のポイント
4.4.6 参考になるソリューション - 多層パーセプトロン
4.4.7 参考になるソリューション - 最近のニューラルネットの発展
4.5 線形モデル
4.5.1 線形モデルの概要
4.5.2 線形モデルの特徴
4.5.3 線形モデルの主なライブラリ
4.5.4 線形モデルの実装
4.5.5 線形モデルの使い方のポイント
4.6 その他のモデル
4.6.1 k近傍法（k-nearest neighbor algorithm，kNN）
4.6.2 ランダムフォレスト（Random Forest，RF）
4.6.3 Extremely Randomized Trees（ERT）
4.6.4 Regularized Greedy Forest（RGF）
4.6.5 Field-aware Factorization Machines（FFM）
4.7 モデルのその他のポイントとテクニック
4.7.1 欠損値がある場合
4.7.2 特徴量の数が多い場合
4.7.3 目的変数に1対1で対応するテーブルでない場合
4.7.4 pseudo labeling
Column 分析コンペ用のクラスやフォルダの構成
第5章　モデルの評価
5.1 モデルの評価とは？
5.2 バリデーションの手法
5.2.1 hold-out法
5.2.2 クロスバリデーション
5.2.3 stratified k-fold
5.2.4 group k-fold
5.2.5 leave-one-out
5.3 時系列データのバリデーション手法
5.3.1 時系列データのhold-out法
5.3.2 時系列データのクロスバリデーション（時系列に沿って行う方法）
5.3.3 時系列データのクロスバリデーション（単純に時間で分割する方法）
5.3.4 時系列データのバリデーションの注意点
5.3.5 Kaggleの「Recruit Restaurant Visitor Forecasting」
5.3.6 Kaggleの「Santander Product Recommendation」
5.4 バリデーションのポイントとテクニック
5.4.1 バリデーションを行う目的
5.4.2 学習データとテストデータの分割をまねる
5.4.3 学習データとテストデータの分布が違う場合
5.4.4 Leaderboardの情報を利用する
5.4.5 バリデーションデータやPublic Leaderboardへの過剰な適合
5.4.6 クロスバリデーションのfoldごとに特徴量を作り直す
5.4.7 使える学習データを増やす
第6章　モデルのチューニング
6.1 パラメータチューニング
6.1.1 ハイパーパラメータの探索手法
6.1.2 パラメータチューニングで設定すること
6.1.3 パラメータチューニングのポイント
6.1.4 ベイズ最適化でのパラメータ探索
6.1.5 GBDTのパラメータおよびそのチューニング
Column xgboostの具体的なパラメータチューニングの方法
6.1.6 ニューラルネットのパラメータおよびそのチューニング
Column 多層パーセプトロンの具体的なパラメータチューニングの方法
6.1.7 線形モデルのパラメータおよびそのチューニング
6.2 特徴選択および特徴量の重要度
6.2.1 単変量統計を用いる方法
6.2.2 特徴量の重要度を用いる方法
6.2.3 反復して探索する方法
6.3 クラスの分布が偏っている場合
Column ベイズ最適化およびTPEのアルゴリズム
第7章　アンサンブル
7.1 アンサンブルとは？
7.2 シンプルなアンサンブル手法
7.2.1 平均，加重平均
7.2.2 多数決，重みづけ多数決
7.2.3 注意点とその他のテクニック
7.3 スタッキング
7.3.1 スタッキングの概要
7.3.2 特徴量作成の方法としてのスタッキング
7.3.3 スタッキングの実装
7.3.4 スタッキングのポイント
7.3.5 hold-outデータへの予測値を用いたアンサンブル
7.4 どんなモデルをアンサンブルすると良いか？
7.4.1 多様なモデルを使う
7.4.2 ハイパーパラメータを変える
7.4.3 特徴量を変える
7.4.4 問題のとらえ方を変える
7.4.5 スタッキングに含めるモデルの選択
7.5 分析コンペにおけるアンサンブルの例
7.5.1 Kaggleの「Otto Group Product Classification Challenge」
7.5.2 Kaggleの「Home Depot Product Search Relevance」
7.5.3 Kaggleの「Home Credit Default Risk」
付　録
A.1 分析コンペの参考資料
A.2 参考文献
A.3 本書で参照した分析コンペ
索引
著者プロフィール
```

### 6. [Kaggle 우승작으로 배우는 머신러닝 탐구생활 파이썬을 활용한 머신러닝 실전 예제 분석](http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9791186697696&orderClick=LAG&Kc=)
* 정권우 지음, 김범준 옮김, 비제이퍼블릭, 2018년 08월 31일 출간, 정가: 27,000원, 판매가: 24,300원, eBook: 21,600원
* 소스코드 다운로드: https://github.com/bjpublic/kaggleml
```
파이썬을 활용한 머신러닝 실전 예제 분석
이 책은 과거 캐글 경진대회에서 제공된 실제 데이터를 다룬다. 머신러닝을 시작하기 위하여 두껍고 어려운 선형대수, 미적분, 통계 책을 읽기 시작하여 고통받고 있는 독자를 위하여, 이 책은 더 재미있고 피부에 와닿는 실제 경진대회를 통해 머신러닝을 배울 수 있도록 돕고자 한다.

먼저, 경진대회에 출제된 문제를 올바르게 이해하고, 데이터 시각화 과정을 통해 데이터에 대한 이해를 쌓아간다. 그리고 높은 순위를 기록한 상위 입상자의 코드를 직접 분석하고 피쳐 엔지니어링, 모델 튜닝, 교차 검증 기법을 독자가 직접 재현할 수 있도록 돕는다. 이 책을 통해 독자는 “성공적인 머신러닝 파이프라인”이 무엇인지를 배우게 될 것이다.

이 책의 특징
- 캐글 경진대회 상위 입상자의 코드를 한 땀 한 땀 분석한다.
- 실제 업계에서 사용하는 Tabular 데이터, 이미지 데이터, 텍스트 데이터, 음성 데이터를 직접 다룬다.
- 최신 머신러닝 모델(XGBoost, LightGBM, CatBoost, PyTorch)을 사용해본다.
```

#### 목차
```
1장 파이썬과 머신러닝 그리고 캐글
1.1 왜 파이썬인가
1.2 왜 캐글인가?
1.3 캐글을 시작하는 방법
1.4 경진대회에 통하는 실질적인 팁
1.5 경진대회 선별 기준

2장 산탄데르 제품 추천 경진대회
2.1 경진대회 소개
2.2 경진대회 주최자의 동기
2.3 평가 척도
2.4 주요 접근
2.5 데이터 준비하기
2.6 탐색적 데이터 분석
2.7 Baseline 모델
2.8 승자의 지혜 - 8등 소스코드 분석
2.9 승자의 지혜

3장 텐서플로 음성 인식 경진대회
3.1 경진대회 소개
3.2 경진대회 주최자의 동기
3.3 평가 척도
3.4 주요 접근
3.5 데이터 준비하기
3.6 탐색적 데이터 분석
3.7 Baseline 모델
3.8 승자의 지혜 - 3등 소스코드 분석
3.9 승자의 지혜

4장 포르토 세구로 안전 운전자 예측 경진대회
4.1 경진대회 소개
4.2 경진대회 주최자의 동기
4.3 평가 척도
4.4 주요 접근
4.5 데이터 준비하기
4.6 탐색적 데이터 분석
4.7 Baseline 모델
4.8 승자의 지혜 - 2등 소스코드 분석
4.9 승자의 지혜

5장 스테이트 팜 산만한 운전자 감지 경진대회
5.1 경진대회 소개
5.2 경진대회 주최자의 동기
5.3 평가 척도
5.4 주요 접근
5.5 데이터 준비하기
5.6 탐색적 데이터 분석
5.7 Baseline 모델
5.8 성능 개선 실험
5.9 승자의 지혜
```

(EOF)
